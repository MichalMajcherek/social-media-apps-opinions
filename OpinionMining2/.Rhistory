MyData <-read.csv("/Users/michal/Politechnika/Projekt/cluster/feat.csv",
header = TRUE, #are there column names in 1st row?
sep = ";", #USE COMA
strip.white = TRUE, #strip out extra white space in strings.
fill = TRUE, #fill in rows that have unequal numbers of columns
comment.char = "#", #character used for comments that should not be read in
stringsAsFactors = FALSE #Another control for deciding whether characters should be converted to factor
)
dtm1 = as.data.frame.matrix(MyData)
dtm1
dtm1 [1:5, ] #1 - docs 2 - term
asd<-dtm1[, 1:3] # select [1:5, 1:2] [ 'all' ,1:2]
#dtm<-dtm1[,-1]
#dtm
asd
#rownames(dtm)
#rownames(dtm)<-asd
filenames <- list.files(getwd(),pattern="*.txt")
filenames <-c(filenames)
filenames
#rownames(dtm)
#rownames(dtm)<-filenames
#filenames
#rownames(asd)
#rownames(asd)<-filenames
rownames(asd) <- c("Facebook", "Instagram", "LinkedIn", "TikTok", "Twitter")
################## EUCLIDIAN ###################### K-MEANS
d1 <- dist(asd, method="euclidian")
kfit <- kmeans(d1, 3) #?????
kfit
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0)
#plot(MyData$Stripes - MyData$Seeds, ylab = "YYY", xlab = "XXX", main = "Data")
########################
library(tm)
library(SnowballC)
library(ggplot2)
library(wordcloud)
library(cluster)
library(fpc)
MyData <-read.csv("/Users/michal/Politechnika/Projekt/cluster/feat.csv",
header = TRUE, #are there column names in 1st row?
sep = ";", #USE COMA
strip.white = TRUE, #strip out extra white space in strings.
fill = TRUE, #fill in rows that have unequal numbers of columns
comment.char = "#", #character used for comments that should not be read in
stringsAsFactors = FALSE #Another control for deciding whether characters should be converted to factor
)
dtm1 = as.data.frame.matrix(MyData)
dtm1
dtm1 [1:5, ] #1 - docs 2 - term
asd<-dtm1[, 1:3] # select [1:5, 1:2] [ 'all' ,1:2]
#dtm<-dtm1[,-1]
#dtm
asd
filenames <- list.files(getwd(),pattern="*.txt")
filenames <-c(filenames)
filenames
rownames(asd) <- c("Facebook", "Instagram", "LinkedIn", "TikTok", "Twitter")
################## EUCLIDIAN ###################### K-MEANS
d1 <- dist(asd, method="euclidian")
kfit <- kmeans(d1, 3) #?????
kfit
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0)
#plot(MyData$Stripes - MyData$Seeds, ylab = "YYY", xlab = "XXX", main = "Data")
#plot(MyData$Stripes - MyData$Seeds, ylab = "YYY", xlab = "XXX", main = "Data")
########################
library(tm)
library(SnowballC)
library(ggplot2)
library(wordcloud)
library(cluster)
library(fpc)
MyData <-read.csv("/Users/michal/Politechnika/Projekt/cluster/app.csv",
header = TRUE, #are there column names in 1st row?
sep = ";", #USE COMA
strip.white = TRUE, #strip out extra white space in strings.
fill = TRUE, #fill in rows that have unequal numbers of columns
comment.char = "#", #character used for comments that should not be read in
stringsAsFactors = FALSE #Another control for deciding whether characters should be converted to factor
)
dtm1 = as.data.frame.matrix(MyData)
dtm1
dtm1 [1:5, ] #1 - docs 2 - term
asd<-dtm1[, 1:3] # select [1:5, 1:2] [ 'all' ,1:2]
#dtm<-dtm1[,-1]
#dtm
asd
filenames <- list.files(getwd(),pattern="*.txt")
filenames <-c(filenames)
filenames
rownames(asd) <- c("Facebook", "Instagram", "LinkedIn", "TikTok", "Twitter")
################## EUCLIDIAN ###################### K-MEANS
d1 <- dist(asd, method="euclidian")
kfit <- kmeans(d1, 3) #?????
kfit
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0)
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0, ylab = "Score", xlab = "EP", main = "App")
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = "Application")
MyData <-read.csv("/Users/michal/Politechnika/Projekt/cluster/comm.csv",
header = TRUE, #are there column names in 1st row?
sep = ";", #USE COMA
strip.white = TRUE, #strip out extra white space in strings.
fill = TRUE, #fill in rows that have unequal numbers of columns
comment.char = "#", #character used for comments that should not be read in
stringsAsFactors = FALSE #Another control for deciding whether characters should be converted to factor
)
dtm1 = as.data.frame.matrix(MyData)
dtm1
dtm1 [1:5, ] #1 - docs 2 - term
asd<-dtm1[, 1:3] # select [1:5, 1:2] [ 'all' ,1:2]
#dtm<-dtm1[,-1]
#dtm
asd
filenames <- list.files(getwd(),pattern="*.txt")
filenames <-c(filenames)
filenames
rownames(asd) <- c("Facebook", "Instagram", "LinkedIn", "TikTok", "Twitter")
################## EUCLIDIAN ###################### K-MEANS
d1 <- dist(asd, method="euclidian")
kfit <- kmeans(d1, 3) #?????
kfit
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = "Application")
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = "Community")
MyData <-read.csv("/Users/michal/Politechnika/Projekt/cluster/exp.csv",
header = TRUE, #are there column names in 1st row?
sep = ";", #USE COMA
strip.white = TRUE, #strip out extra white space in strings.
fill = TRUE, #fill in rows that have unequal numbers of columns
comment.char = "#", #character used for comments that should not be read in
stringsAsFactors = FALSE #Another control for deciding whether characters should be converted to factor
)
dtm1 = as.data.frame.matrix(MyData)
dtm1
dtm1 [1:5, ] #1 - docs 2 - term
asd<-dtm1[, 1:3] # select [1:5, 1:2] [ 'all' ,1:2]
#dtm<-dtm1[,-1]
#dtm
asd
filenames <- list.files(getwd(),pattern="*.txt")
filenames <-c(filenames)
filenames
rownames(asd) <- c("Facebook", "Instagram", "LinkedIn", "TikTok", "Twitter")
################## EUCLIDIAN ###################### K-MEANS
d1 <- dist(asd, method="euclidian")
kfit <- kmeans(d1, 3) #?????
kfit
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = "Community")
#plot(MyData$Stripes - MyData$Seeds, ylab = "YYY", xlab = "XXX", main = "Data")
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = "User Experience")
library(tm)
library(SnowballC)
library(ggplot2)
library(wordcloud)
library(cluster)
library(fpc)
MyData <-read.csv("/Users/michal/Politechnika/Projekt/cluster/feat.csv",
header = TRUE, #are there column names in 1st row?
sep = ";", #USE COMA
strip.white = TRUE, #strip out extra white space in strings.
fill = TRUE, #fill in rows that have unequal numbers of columns
comment.char = "#", #character used for comments that should not be read in
stringsAsFactors = FALSE #Another control for deciding whether characters should be converted to factor
)
dtm1 = as.data.frame.matrix(MyData)
dtm1
dtm1 [1:5, ] #1 - docs 2 - term
asd<-dtm1[, 1:3] # select [1:5, 1:2] [ 'all' ,1:2]
#dtm<-dtm1[,-1]
#dtm
asd
#rownames(dtm)
#rownames(dtm)<-asd
filenames <- list.files(getwd(),pattern="*.txt")
filenames <-c(filenames)
filenames
#rownames(dtm)
#rownames(dtm)<-filenames
#filenames
#rownames(asd)
#rownames(asd)<-filenames
rownames(asd) <- c("Facebook", "Instagram", "LinkedIn", "TikTok", "Twitter")
################## EUCLIDIAN ###################### K-MEANS
d1 <- dist(asd, method="euclidian")
kfit <- kmeans(d1, 3) #?????
kfit
clusplot(as.matrix(d1), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = "Features")
########## Instagram #################
library(tm)
library(SnowballC)
library(ggplot2)
library(wordcloud)
#Setting working directory
setwd("/Users/michal/Politechnika/Projekt/OpinionMining2") #!!!!!!!!!!CHANGE!!!!!!!!!
wd<-"/Users/michal/Politechnika/Projekt/OpinionMining2"#!!!!!!!!!!CHANGE!!!!!!!!!
dir(wd)
stopwords<-"/Users/michal/Politechnika/Projekt/stopwords.txt"
dir(stopwords)
#Read CSV Brand Database
Com<-read.csv("/Users/michal/Politechnika/Projekt/OpinionMining2/instagram.csv", #!!!!!!!!!!CHANGE!!!!!!!!!
header = TRUE,
sep = "\t",
strip.white = TRUE,
fill = TRUE, comment.char = "#",
stringsAsFactors = FALSE
)
head(Com)
#Com
#Matrix from Brand Database
ComDF = as.data.frame.matrix(Com)
Comments1 <- ComDF [,1]
Comments1
Comments <- VCorpus(VectorSource(Comments1))
Comments
writeLines(as.character(Comments [[1]]))
#Get only comments column
getTransformations()
#Remove Punctuation and Numbers
Comments <- tm_map(Comments , tolower)
writeLines(as.character(Comments [[1]]))
Comments <- tm_map(Comments ,removePunctuation)
writeLines(as.character(Comments [[1]]))
Comments <- tm_map(Comments , removeNumbers)
writeLines(as.character(Comments [[1]]))
#Remove special characters
for (j in seq(Comments)) { # usuwa znaki charakterystyczna dla maili
Comments[[j]] <- gsub("/", " ", Comments[[j]])
Comments[[j]] <- gsub("@", " ", Comments[[j]])
Comments[[j]] <- gsub("–", " ", Comments[[j]])
Comments[[j]] <- gsub("’", " ", Comments[[j]])
Comments[[j]] <- gsub("“", " ", Comments[[j]])
Comments[[j]] <- gsub("‘", " ", Comments[[j]])
Comments[[j]] <- gsub(")", " ", Comments[[j]])
Comments[[j]] <- gsub("”", " ", Comments[[j]])
}
writeLines(as.character(Comments [[1]]))
#Remove english stopwords
Comments <- tm_map(Comments , removeWords, stopwords("English"))
writeLines(as.character(Comments [[1]]))
#Remove Special Stopwords
StW <- read.table("/Users/michal/Politechnika/Projekt/stopwords.txt")
StWW <- as.character(StW$V1)
StWW
Comments <- tm_map(Comments , removeWords, StWW)
Comments <- tm_map(Comments , PlainTextDocument) #bez tego nie działa DTM COMMENTS
writeLines(as.character(Comments [[1]]))
#Remove withespace
for (j in seq(Comments)) {
Comments [[j]]<-stemDocument(Comments [[j]], language = "english") }
Comments
writeLines(as.character(Comments [[1]]))
dtm <- DocumentTermMatrix(Comments)
#inspect(dtm[1:1,10:100])
m <- as.matrix(dtm)
write.csv(m, file="/Users/michal/Politechnika/Projekt/excel2_ig/DocumentTermMatrix.csv") #!!!!!!!!!!CHANGE!!!!!!!!!
dtm
library(tm)
library(topicmodels)
library(lsa)
library(scatterplot3d)
library(ggplot2)
#check the presence of rows with a zero's sum
raw.sum=apply(dtm,1,FUN=sum) #sum by raw for each raw of the table
raw.sum
#number of rows with a zero's sum
mmm<-nrow(dtm[raw.sum==0,])
mmm
# if mmm=0, only create dtm2 and NN (number of rows in DTM)
# if mmm>0, delete the rows with zero's sum form corpus
if (mmm==0) {
dtm2<-dtm
NN<-nrow(dtm2)
NN
} else {
dtm2<-dtm[raw.sum!=0,]
NN<-nrow(dtm2)
}
NN
######### wordcloud ###############
freq <- colSums(as.matrix(dtm)) #zliczamy ile kolumn i mamy ilosc słów
length(freq)
library(wordcloud)
set.seed(142)
dark2 <- brewer.pal(6, "Dark2")
wordcloud(names(freq), freq, max.words=100, rot.per=0.2, random.order=FALSE, colors=dark2)
####################### LDA Topic Modelling ######################
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
k <- 4
ldaOut <-LDA(dtm2, k, method="Gibbs", control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
ldaOut.terms <- as.matrix(terms(ldaOut,5))
ldaOut.terms
ldaOut.topics <- as.matrix(topics(ldaOut))
ldaOut.topics
####################### Rows numbering ######################
nrow(ldaOut.topics) #komentarze mają konkretny numer i przydzielony numer tematu
Comment<-seq(1, NN, by=1)
Comment
wf=data.frame(Comment=Comment, Topics=ldaOut.topics)
wf
####################### Builing SubCorpus of Topic 1 ######################
topic1<-wf[wf[2] == 1,] #find Topic 1
topic1$Comment
#number of comments with Topic 1
kk1<-nrow(topic1)
kk1
kk<-nrow(dtm2)
kk
list1<-c()
i=1
while(i<=kk) {
if (wf[i,2]==1) {     #find Topic 1
list1<-c(list1,i)
}
i=i+1
}
list1
wf1=NULL
for (i in 1:kk) {
for (j in 1:kk1) {
if (i==list1[j]){
c <- data.frame(file=as.character(wf[list1[j],1]),document=as.character(Comments[[i]]))
wf1=rbind(wf1,c)
}
}
}
wf1
wf1$document[1]
####################### Corpus Creating ######################
Topic_1_docs <- Corpus(VectorSource(as.character(wf1$document)))
writeLines(as.character(Topic_1_docs[[1]]))
####################### Writing in CSV File_ with Comments of Topic 1######################
mycorpus_dataframe <- data.frame(text=wf1$document, stringsAsFactors=F)
mycorpus_dataframe
write.csv(mycorpus_dataframe,'/Users/michal/Politechnika/Projekt/excel2_ig/Topic1_comments.csv', row.names=FALSE) #!!!!!!!!!!CHANGE!!!!!!!!!
####################### Builing SubCorpus of Topic 2 ######################
topic2<-wf[wf[2] == 2,] #find Topic 2
topic2$Comment
#number of comments with Topic 2
kk2<-nrow(topic2)
kk2
kk<-nrow(dtm2)
kk
list2<-c()
i=1
while(i<=kk) {
if (wf[i,2]==2) {     #find Topic 2
list2<-c(list2,i)
}
i=i+1
}
list2
wf2=NULL
for (i in 1:kk) {
for (j in 1:kk2) {
if (i==list2[j]){
c <- data.frame(file=as.character(wf[list2[j],1]),document=as.character(Comments[[i]]))
wf2=rbind(wf2,c)
}
}
}
wf2
wf2$document[1]
####################### Corpus Creating ######################
Topic_2_docs <- Corpus(VectorSource(as.character(wf2$document)))
writeLines(as.character(Topic_2_docs[[1]])) #ERROR ERROR ERROR ERROR
####################### Writing in CSV File_ with Comments of Topic 2 ######################
mycorpus_dataframe <- data.frame(text=wf2$document, stringsAsFactors=F)
mycorpus_dataframe
write.csv(mycorpus_dataframe,'/Users/michal/Politechnika/Projekt/excel2_ig/Topic2_comments.csv', row.names=FALSE) #!!!!!!!!!!CHANGE!!!!!!!!!
####################### Builing SubCorpus of Topic 3 ######################
topic3<-wf[wf[2] == 3,] #find Topic 3
topic3$Comment
#number of comments with Topic 3
kk3<-nrow(topic3)
kk3
kk<-nrow(dtm2)
kk
list3<-c()
i=1
while(i<=kk) {
if (wf[i,2]==3) {     #find Topic 3
list3<-c(list3,i)
}
i=i+1
}
list3
wf3=NULL
for (i in 1:kk) {
for (j in 1:kk3) {
if (i==list3[j]){
c <- data.frame(file=as.character(wf[list3[j],1]),document=as.character(Comments[[i]]))
wf3=rbind(wf3,c)
}
}
}
wf3
wf3$document[1]
####################### Corpus Creating ######################
Topic_3_docs <- Corpus(VectorSource(as.character(wf3$document)))
writeLines(as.character(Topic_3_docs[[1]]))
####################### Writing in CSV File_ with Comments of Topic 3 ######################
mycorpus_dataframe <- data.frame(text=wf3$document, stringsAsFactors=F)
mycorpus_dataframe
write.csv(mycorpus_dataframe,'/Users/michal/Politechnika/Projekt/excel2_ig/Topic3_comments.csv', row.names=FALSE) #!!!!!!!!!!CHANGE!!!!!!!!!
####################### Builing SubCorpus of Topic 4 ######################
topic4<-wf[wf[2] == 4,] #find Topic 4
topic4$Comment
#number of comments with Topic 4
kk4<-nrow(topic4)
kk4
kk<-nrow(dtm2)
kk
list4<-c()
i=1
while(i<=kk) {
if (wf[i,2]==4) {     #find Topic 4
list4<-c(list4,i)
}
i=i+1
}
list4
wf4=NULL
for (i in 1:kk) {
for (j in 1:kk4) {
if (i==list4[j]){
c <- data.frame(file=as.character(wf[list4[j],1]),document=as.character(Comments[[i]]))
wf4=rbind(wf4,c)
}
}
}
wf4
wf4$document[1]
####################### Corpus Creating ######################
Topic_4_docs <- Corpus(VectorSource(as.character(wf4$document)))
writeLines(as.character(Topic_4_docs[[1]]))
####################### Writing in CSV File_ with Comments of Topic 4 ######################
mycorpus_dataframe <- data.frame(text=wf4$document, stringsAsFactors=F)
mycorpus_dataframe
write.csv(mycorpus_dataframe,'/Users/michal/Politechnika/Projekt/excel2_ig/Topic4_comments.csv', row.names=FALSE) #!!!!!!!!!!CHANGE!!!!!!!!!
#________________________________________________________________________
#____________________SENTIMENT ANALYSIS__________________________________
###############################################################################################
###################################### SENTIMENT_1st OPTION1 ##############
library("plyr")
library("stringr")
neg=scan("/Users/michal/Politechnika/Projekt/Lexicon/negative-words.txt", what="character", comment.char =";" )
pos=scan("/Users/michal/Politechnika/Projekt/Lexicon/positive-words.txt", what="character" ,comment.char =";" )
#__________Initialization of the Sentiment analysis Procedure_______________
score.sentiment = function(docs, pos.words, neg.words, .progress='none')
{
scores = laply(docs_s, function(docs, pos.words, neg.words)
{
word.list = str_split(docs, '\\s+')
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=docs)
return(scores.df)
}
####################### Topic 1 Sentiment Scoring #######################
# COPY IT
####################### Topic 1 Sentiment Scoring #######################
# COPY IT
result=c()
docs<-Topic_1_docs #replace it from 2 to 5 Topic
m1=c()
for (j in seq(docs)) {
docs_s=as.character(docs[[j]])
print(docs_s)
result = score.sentiment(docs_s, pos, neg)
newRow1 <- data.frame(Doc=j,Score = result$score, Documents = result$text)
#print(newRow1)
m1<- rbind(m1,newRow1)
#print(m1)
}
m1
#______________________Statistics______________________
summary(m1$Score)
#______________________Histogram_1_____________________
hist(m1$Score,
main="Histogram for the Sentiment by Topic: Application",
xlab="Scores",
ylab="Number of of Opinions",
border="blue",
col="grey",
)
#______________________Histogram_2_____________________
hist(m1$Score,
main="Histogram for the Sentiment by Topic: Application",
xlab="Scores",
ylab="Probability",
border="blue",
col="grey",
prob = TRUE
)
lines(density(m1$Score))
m11<-as.matrix(m1)
m11
write.csv(m11, file="/Users/michal/Politechnika/Projekt/excel2_ig/Sent_1.csv") #!!!!!!!!!!CHANGE!!!!!!!!!
